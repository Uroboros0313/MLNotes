{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7ff6ba",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1ea14",
   "metadata": {},
   "source": [
    "面对神经网络大维度的参数，Backpropagation是一种让Gradient Descent更有效率的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88d394",
   "metadata": {},
   "source": [
    "## Chain Rule（链式法则）      \n",
    "- **Case 1**      \n",
    "$$y= g(x) \\text{  }  z=h(y)$$\n",
    "$$\\Delta x \\rightarrow \\Delta y \\rightarrow \\Delta z$$\n",
    "$$\\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx}$$\n",
    "- **Case 2**   \n",
    "$$x=g(s) \\text{  }  y=h(s) \\text{  } z=k(x,y)$$\n",
    "$$\\Delta s \\rightarrow \\Delta x \\rightarrow \\Delta z$$\n",
    "$$\\Delta s \\rightarrow \\Delta y \\rightarrow \\Delta z$$\n",
    "$$\\frac{dz}{ds}=\\frac{\\partial z}{\\partial x}\\frac{dx}{ds}+\\frac{\\partial z}{\\partial y}\\frac{dy}{ds}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8146b97a",
   "metadata": {},
   "source": [
    "$$L(\\theta)=\\sum^N_{n=1}C^n(\\theta)\\rightarrow\\frac{\\partial L(\\theta)}{\\partial w}=\\sum^N_{n=1}\\frac{\\partial C^n(\\theta)}{\\partial w}$$    \n",
    "$C(\\theta)$是定义的一个预测值（输出值）$\\hat y_i$与真实值$y_i$的距离     \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80159d03",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"resource_pic/Class5.Backpropagation_1.PNG\" width=600 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc93d3",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial C}{\\partial w}=\\frac{\\partial z}{\\partial w} \\frac{\\partial C}{\\partial z}$$  \n",
    "\n",
    "**Forward Pass:**     \n",
    "    对所有参数计算$\\partial z / \\partial w$     \n",
    "    \n",
    "**Backward Pass:**     \n",
    "    对所有输入激活函数的$z$**($x$的线性组合，输入Sigmoid前的z)**计算$\\partial C / \\partial z$    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b046a",
   "metadata": {},
   "source": [
    "### **Forward Pass:**     \n",
    "$$z=w_1x_1+w_2+x_2 \\cdots,\\frac{\\partial z }{\\partial w}=x=[x_1,x_2,x_3,\\cdots]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c372fd1",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"resource_pic/Class5.Backpropagation_2.PNG\" width=600 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e27e3",
   "metadata": {},
   "source": [
    "### **Backward Pass:**     \n",
    "$$\\frac{\\partial C}{\\partial z}=\\frac{\\partial a}{\\partial z}\\frac{\\partial C }{\\partial a}$$   \n",
    "$$\\frac{\\partial C}{\\partial a}=\\frac{\\partial z'}{\\partial a} \\frac{\\partial C}{\\partial z'}+\\frac{\\partial z''}{\\partial a} \\frac{\\partial C}{\\partial z''}$$\n",
    "$$\\frac{\\partial C}{\\partial z}=\\sigma(z)'(\\frac{\\partial z'}{\\partial a} \\frac{\\partial C}{\\partial z'}+\\frac{\\partial z''}{\\partial a} \\frac{\\partial C}{\\partial z''})$$\n",
    "\n",
    "其中$\\cfrac{\\partial z'}{\\partial a}=w_3,\\cfrac{\\partial z''}{\\partial a}=w_4$,见下图       \n",
    "其中$a=\\sigma (z)$，即Sigmoid激活函数，$a$也作为下一个激活函数$z'$的输入值    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7211ab9e",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"resource_pic/Class5.Backpropagation_3.PNG\" width=600 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6e3b0",
   "metadata": {},
   "source": [
    "假设一个反向的神经网络，有$\\sigma(z)'$是一个在前向传播时确定的常数，所用的公式与正向的神经网络相同    \n",
    "假设下一层既是Output Layer      \n",
    "$$\\frac{\\partial C}{\\partial z'}=\\frac{\\partial y_1}{\\partial z'} \\frac{\\partial C}{\\partial y'}+\\frac{\\partial y_2}{\\partial z''} \\frac{\\partial C}{\\partial y_2}$$      \n",
    "其中$C(y_i)$是估计值（预测值）的Loss Function    \n",
    "因此在计算神经网络时，先计算Loss Function对输出值的导数，再向前传播"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08481fc3",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"resource_pic/Class_5.Backpropagation_4.PNG\" width=600 height=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d392877",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"resource_pic/Class_5.Backpropagation_5.PNG\" width=600 height=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e89ee9d0",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"resource_pic/Class_5.Backpropagation_6.PNG\" width=600 height=600>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
