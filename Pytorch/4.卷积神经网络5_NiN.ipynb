{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81548cb2",
   "metadata": {},
   "source": [
    "# NiN\n",
    "## NiN块\n",
    "\n",
    "卷积层的输入和输出通常是四维数组`（样本，通道，高，宽）`，而全连接层的输入和输出则通常是二维数组`（样本，特征）`。\n",
    "\n",
    "如果想**在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维**。\n",
    "\n",
    "NiN使用`1×1`卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。\n",
    "\n",
    "卷积层:\n",
    "\n",
    "`第一层:kernel_size`            \n",
    "\n",
    "`第二层:1x1`          \n",
    "\n",
    "`第三层:kernel_size`            \n",
    "\n",
    "`第四层:1x1`\n",
    "\n",
    "<img style=\"float: center;\" src=\"./pics/4.nin.png\" width=400 height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c021d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T09:20:15.266788Z",
     "start_time": "2022-02-05T09:20:12.767432Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "def nin_block(in_channels,out_channels,kernel_size,stride,padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels,out_channels,kernel_size = 1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels,out_channels,kernel_size = 1),\n",
    "                        nn.ReLU()\n",
    "                       )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b825e",
   "metadata": {},
   "source": [
    "## NiN模型\n",
    "NiN使用卷积窗口形状分别为`11×11`、`5×5`和`×3`的卷积层。每个NiN块后接一个`步幅为2`、`窗口形状为3×3`的最大池化层。\n",
    "\n",
    "NiN去掉了AlexNet最后的3个全连接层.                \n",
    "\n",
    "NiN使用了`输出通道数等于标签类别数的NiN块`，然后使用`全局平均池化层`对每个通道中所有元素求平均并直接用于分类。\n",
    "\n",
    "这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN的这个设计的好处是可以`显著减小模型参数尺寸，从而缓解过拟合`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb2ab10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T09:20:15.298780Z",
     "start_time": "2022-02-05T09:20:15.267865Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return F.avg_pool2d(x,kernel_size = x.size()[2:])\n",
    "    \n",
    "net = nn.Sequential(\n",
    "    nin_block(1,96,kernel_size = 11,stride = 4,padding = 0),\n",
    "    nn.MaxPool2d(kernel_size = 3 ,stride = 2),\n",
    "    nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n",
    "    GlobalAvgPool2d(), \n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)\n",
    "    d2l.FlattenLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20c53b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T09:20:16.035150Z",
     "start_time": "2022-02-05T09:20:15.299778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 output shape:  torch.Size([1, 96, 54, 54])\n",
      "1 output shape:  torch.Size([1, 96, 26, 26])\n",
      "2 output shape:  torch.Size([1, 256, 26, 26])\n",
      "3 output shape:  torch.Size([1, 256, 12, 12])\n",
      "4 output shape:  torch.Size([1, 384, 12, 12])\n",
      "5 output shape:  torch.Size([1, 384, 5, 5])\n",
      "6 output shape:  torch.Size([1, 384, 5, 5])\n",
      "7 output shape:  torch.Size([1, 10, 5, 5])\n",
      "8 output shape:  torch.Size([1, 10, 1, 1])\n",
      "9 output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 1, 224, 224)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376ed906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T09:27:55.587569Z",
     "start_time": "2022-02-05T09:20:16.037393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:27<00:00,  5.38it/s]\n",
      "  0%|                                                                                          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.4093, train acc 0.463, test acc 0.755, time 95.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:24<00:00,  5.53it/s]\n",
      "  0%|                                                                                          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.5745, train acc 0.792, test acc 0.814, time 92.0 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:23<00:00,  5.60it/s]\n",
      "  0%|                                                                                          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 0.4624, train acc 0.832, test acc 0.845, time 91.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:22<00:00,  5.67it/s]\n",
      "  0%|                                                                                          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss 0.4127, train acc 0.849, test acc 0.850, time 90.2 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [01:22<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss 0.3731, train acc 0.864, test acc 0.864, time 90.4 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224,root = \"D:\\JupyterFile\\Machine_Learning\\Pytorch\\Datasets\\FashionMNIST\")\n",
    "\n",
    "lr, num_epochs = 0.002, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
