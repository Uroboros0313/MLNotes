{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5763b8",
   "metadata": {},
   "source": [
    "# 批量归一化         \n",
    "\n",
    "`批量归一化（batch normalization）层`——能让较深的神经网络的训练变得更加容易\n",
    "\n",
    "\n",
    "通常来说，`数据标准化预处理对于浅层模型就足够有效了`。随着模型训练的进行，**当每层中参数更新时，靠近输出层的输出较难出现剧烈变化**。\n",
    "\n",
    "对**深层神经网络**来说，即使输入数据已做标准化，**训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化**。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d89478",
   "metadata": {},
   "source": [
    "## 批量归一化层\n",
    "### 对全连接层做批量归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586a06e",
   "metadata": {},
   "source": [
    "### 对卷积层做批量归一化\n",
    "对卷积层来说，批量归一化发生在`卷积计算之后、应用激活函数之前`。如果卷积计算输出多个通道，需要`对这些通道的输出分别做批量归一化`，且`每个通道都拥有独立的拉伸和偏移参数，并均为标量`。\n",
    "\n",
    "\n",
    "### 预测时的批量归一化\n",
    "`使用批量归一化训练时，我们可以将批量大小设得大一点，从而使批量内样本的均值和方差的计算都较为准确`。将训练好的模型用于预测时，我们希望模型对于任意输入都有确定的输出。因此，`单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差`。一种常用的方法是`通过移动平均估算整个训练数据集的样本均值和方差`，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，`批量归一化层在训练模式和预测模式下的计算结果也是不一样的`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d82d950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T13:13:09.265809Z",
     "start_time": "2022-02-05T13:13:06.789897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557550e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T13:13:09.281492Z",
     "start_time": "2022-02-05T13:13:09.266423Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def batch_norm(is_training,X,gamma,beta,moving_mean,moving_var,eps,momentum):\n",
    "    if not is_training:\n",
    "        X_hat = (X - moving_mean)/torch.sqrt(moving_var + eps)\n",
    "        \n",
    "    else:\n",
    "        assert len(X.shape) in (2,4)\n",
    "        if len(X.shape) == 2:\n",
    "            mean = X.mean(dim = 0)\n",
    "            var = ((X-mean)**2).mean(dim = 0)\n",
    "            \n",
    "        else:\n",
    "            mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "        # 训练模式下用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "            \n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum)*mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum)*var\n",
    "    Y = gamma * X_hat + beta\n",
    "    \n",
    "    return Y,moving_mean,moving_var\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b0a63",
   "metadata": {},
   "source": [
    "接下来，自定义一个`BatchNorm层`。它保存`参与求梯度和迭代的拉伸参数gamma和偏移参数beta`，同时也维护移动平均得到的均值和方差，以便能够在模型预测时被使用。BatchNorm实例所需指定的`num_features参数`对于全连接层来说应为`输出个数`，对于卷积层来说则为`输出通道数`。该实例所需指定的`num_dims`参数对于全连接层和卷积层来说分别为`2和4`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5272d596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T13:13:09.296767Z",
     "start_time": "2022-02-05T13:13:09.282485Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self,num_features,num_dims):\n",
    "        super(BatchNorm,self).__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1,num_features)\n",
    "        else:\n",
    "            shape = (1,num_features,1,1)\n",
    "            \n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.zeros(shape)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var, Module实例的traning属性默认为true, 调用.eval()后设成false\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(self.training, \n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5a9805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T13:14:02.447336Z",
     "start_time": "2022-02-05T13:13:09.297767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:11<00:00, 20.13it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.9939, train acc 0.785, test acc 0.831, time 13.9 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:07<00:00, 31.72it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.4610, train acc 0.863, test acc 0.850, time 9.8 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:07<00:00, 30.96it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 0.3673, train acc 0.879, test acc 0.861, time 9.9 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:07<00:00, 31.87it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss 0.3315, train acc 0.887, test acc 0.833, time 9.7 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:07<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss 0.3077, train acc 0.894, test acc 0.882, time 9.7 sec\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            BatchNorm(6, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            BatchNorm(16, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            BatchNorm(120, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            BatchNorm(84, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b575343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T14:03:04.037408Z",
     "start_time": "2022-02-05T14:02:02.287784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:09<00:00, 25.21it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.0067, train acc 0.780, test acc 0.815, time 12.2 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:09<00:00, 25.43it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.4714, train acc 0.860, test acc 0.848, time 12.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:09<00:00, 24.85it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 0.3752, train acc 0.875, test acc 0.834, time 12.5 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:09<00:00, 25.17it/s]\n",
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss 0.3378, train acc 0.884, test acc 0.836, time 12.3 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:09<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss 0.3167, train acc 0.889, test acc 0.845, time 12.5 sec\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
