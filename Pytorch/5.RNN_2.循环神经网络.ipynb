{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995558be",
   "metadata": {},
   "source": [
    "# 含隐藏状态的循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7480ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.233803Z",
     "start_time": "2022-03-20T10:36:53.798699Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6244,  0.8535,  3.6138, -1.4100],\n",
       "        [-3.5620,  0.7390,  1.3317, -0.8977],\n",
       "        [ 2.0508, -0.7742, -2.4926,  0.5569]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X,W_xh = torch.randn(3,1),torch.randn(1,4)\n",
    "H,W_hh = torch.randn(3,4),torch.randn(4,4)\n",
    "torch.matmul(X,W_xh)+torch.matmul(H,W_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fb599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.258052Z",
     "start_time": "2022-03-20T10:36:56.241811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6244,  0.8535,  3.6138, -1.4100],\n",
       "        [-3.5620,  0.7390,  1.3317, -0.8977],\n",
       "        [ 2.0508, -0.7742, -2.4926,  0.5569]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.cat((X,H),dim = 1),torch.cat((W_xh,W_hh),dim = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb93b6ca",
   "metadata": {},
   "source": [
    "# 语言模型数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d7ece",
   "metadata": {},
   "source": [
    "## 建立字符索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca7c690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.292807Z",
     "start_time": "2022-03-20T10:36:56.260807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('./data/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open(\"jaychou_lyrics.txt\") as f:\n",
    "        corpus_chars = f.read().decode(\"utf-8\")\n",
    "corpus_chars[:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7beb76b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.308805Z",
     "start_time": "2022-03-20T10:36:56.292807Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_chars = corpus_chars.replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "corpus_chars = corpus_chars[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abd8367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.324804Z",
     "start_time": "2022-03-20T10:36:56.308805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027\n"
     ]
    }
   ],
   "source": [
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char,i) for i,char in enumerate(idx_to_char)])\n",
    "vocab_size = len(char_to_idx)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61158937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.340803Z",
     "start_time": "2022-03-20T10:36:56.324804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars: 想要有直升机 想要和你飞到宇宙去 想要和\n",
      "indices: [881, 398, 1017, 546, 473, 814, 262, 881, 398, 319, 634, 766, 439, 357, 655, 747, 262, 881, 398, 319]\n"
     ]
    }
   ],
   "source": [
    "corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "sample = corpus_indices[:20]\n",
    "print(\"chars:\",\"\".join([idx_to_char[idx] for idx in sample]))\n",
    "print(\"indices:\",sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815c101",
   "metadata": {},
   "source": [
    "## 时序数据采样\n",
    "\n",
    "假设时间步数为5，样本序列为5个字符，即“想”“要”“有”“直”“升”。该样本的标签序列为这些字符分别在训练集中的下一个字符，即“要”“有”“直”“升”“机”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b426ef",
   "metadata": {},
   "source": [
    "### 随机采样\n",
    "\n",
    "我们无法用**一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态**。在训练模型时，每次随机采样前都需要重新初始化隐藏状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2998d088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:56.356805Z",
     "start_time": "2022-03-20T10:36:56.340803Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_iter_random(corpus_indices,batch_size,num_steps,device = None):\n",
    "    num_examples = (len(corpus_indices) - 1)//num_steps\n",
    "    epoch_size = num_examples//batch_size\n",
    "    example_indices = list(range(num_examples))\n",
    "    random.shuffle(example_indices)\n",
    "    \n",
    "    def _data(pos):\n",
    "        return corpus_indices[pos:pos+num_steps]\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        i = i * batch_size\n",
    "        batch_indices = example_indices[i:i+batch_size]\n",
    "        X = [_data(j*num_steps) for j in batch_indices]\n",
    "        Y = [_data(j*num_steps+1) for j in batch_indices]\n",
    "        \n",
    "        yield torch.tensor(X,dtype = torch.float32,device = device),\\\n",
    "        torch.tensor(Y,dtype = torch.float32,device = device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf689548",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:57.137180Z",
     "start_time": "2022-03-20T10:36:56.356805Z"
    }
   },
   "outputs": [],
   "source": [
    "my_seq = list(range(30))\n",
    "for X,Y in data_iter_random(my_seq , batch_size = 8 , num_steps = 6):\n",
    "    print(\"X:\",X,\"\\nY:\",Y,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939ecf4",
   "metadata": {},
   "source": [
    "### 相邻采样\n",
    "\n",
    "可以令相邻的两个随机小批量在原始序列上的位置相毗邻。\n",
    "\n",
    "可以**用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态**，从而使下一个小批量的输出也取决于当前小批量的输入，并如此循环下去。\n",
    "\n",
    "这对实现循环神经网络造成了两方面影响：\n",
    "\n",
    "1.  在训练模型时，**只需在每一个迭代周期开始时初始化隐藏状态**；\n",
    "\n",
    "\n",
    "2. 当多个相邻小批量通过传递隐藏状态串联起来时，模型参数的梯度计算将依赖所有串联起来的小批量序列。同一迭代周期中，随着迭代次数的增加，梯度的计算开销会越来越大。 为了使模型参数的梯度计算只依赖一次迭代读取的小批量序列，**可以在每次读取小批量前将隐藏状态从计算图中分离出来。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46785acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:57.153217Z",
     "start_time": "2022-03-20T10:36:57.137180Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps,device = None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    corpus_indices = torch.tensor(corpus_indices,dtype = torch.float32,device = device)\n",
    "    data_len = len(corpus_indices)\n",
    "    batch_len = data_len // batch_size\n",
    "    indices = corpus_indices[0:batch_size*batch_len].view(batch_size,batch_len)\n",
    "    epoch_size = (batch_len - 1)//num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        i = i * num_steps\n",
    "        X = indices[:, i : i + num_steps]\n",
    "        Y = indices[:, i + 1 : i + num_steps + 1]\n",
    "        yield X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94dfa1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:58.639855Z",
     "start_time": "2022-03-20T10:36:57.153217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [15., 16., 17., 18., 19., 20.]], device='cuda:0') \n",
      "Y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [16., 17., 18., 19., 20., 21.]], device='cuda:0') \n",
      "\n",
      "X:  tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [21., 22., 23., 24., 25., 26.]], device='cuda:0') \n",
      "Y: tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [22., 23., 24., 25., 26., 27.]], device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X, Y in data_iter_consecutive(my_seq, batch_size=2, num_steps=6):\n",
    "    print('X: ', X, '\\nY:', Y, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5c80a",
   "metadata": {},
   "source": [
    "# 循环神经网络的从零开始实现\n",
    "\n",
    "在本节中，我们将从零开始实现一个基于字符级循环神经网络的语言模型，并在周杰伦专辑歌词数据集上训练一个模型来进行歌词创作。首先，我们读取周杰伦专辑歌词数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d2b7fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T10:36:59.733883Z",
     "start_time": "2022-03-20T10:36:58.639855Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a085905",
   "metadata": {},
   "source": [
    "## one-hot向量\n",
    "假设词典中不同字符的数量为`N`（即词典大小vocab_size），每个字符已经同一个从0到`N-1`的连续整数值索引一一对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ffb8ad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T11:45:46.002619Z",
     "start_time": "2022-03-20T11:45:45.981619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(x,n_class,dtype = torch.float32):\n",
    "    # X shape: (batch) , output shape : (batch,n_class)\n",
    "    x = x.long()\n",
    "    res = torch.zeros(x.shape[0] , n_class , dtype = dtype ,device = x.device)\n",
    "    res.scatter_(1 , x.view(-1,1) , 1)\n",
    "    \n",
    "    return res\n",
    "\n",
    "x = torch.tensor([0, 2])\n",
    "one_hot(x, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedab27d",
   "metadata": {},
   "source": [
    "我们每次采样的小批量的形状是(批量大小, 时间步数)。下面的函数将这样的小批量变换成数个可以输入进网络的形状为(批量大小, 词典大小)的矩阵，矩阵个数等于时间步数。也就是说，时间步`t`的输入为$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$\n",
    " ，其中`n`为批量大小，`d`为输入个数，即`one-hot`向量长度（词典大小）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b739917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T11:49:54.931519Z",
     "start_time": "2022-03-20T11:49:54.911532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027])\n"
     ]
    }
   ],
   "source": [
    "def to_onehot(X,n_class):\n",
    "    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\n",
    "    return [one_hot(X[:,i],n_class) for i in range(X.shape[1])]\n",
    "\n",
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = to_onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf6e24",
   "metadata": {},
   "source": [
    "## 初始化模型参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
