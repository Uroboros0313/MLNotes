{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 二维卷积层\n",
    "\n",
    "卷积(互相关运算):接受输入数组`X`与核数组`K`，并输出数组`Y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 互相关运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:43:59.437676Z",
     "start_time": "2022-02-03T06:43:58.731150Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:43:59.452819Z",
     "start_time": "2022-02-03T06:43:59.437676Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d(X, K): \n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维卷积层\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个**标量偏差**来得到输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:43:59.468890Z",
     "start_time": "2022-02-03T06:43:59.453819Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像中物体边缘检测\n",
    "\n",
    "检测图像中物体的边缘，即找到像素变化的位置。首先我们构造一张`6×86×8`的图像（即高和宽分别为`6`像素和`8`像素的图像）。它中间4列为`黑（0）`，其余为`白（1）`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:43:59.483862Z",
     "start_time": "2022-02-03T06:43:59.469889Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "K = torch.tensor([[1, -1]])\n",
    "Y = corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:43:59.499822Z",
     "start_time": "2022-02-03T06:43:59.484864Z"
    },
    "scrolled": false,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "K\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过数据学习核数组\n",
    "\n",
    "- 例子: 使用**物体边缘检测中的输入数据X**和输出数据Y来学习我们构造的核数组K。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:00.209611Z",
     "start_time": "2022-02-03T06:43:59.501819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5, loss 7.452\n",
      "Step 10, loss 2.052\n",
      "Step 15, loss 0.569\n",
      "Step 20, loss 0.158\n"
     ]
    }
   ],
   "source": [
    "# 构造一个核数组形状是(1, 2)的二维卷积层\n",
    "conv2d = Conv2D(kernel_size=(1, 2))\n",
    "\n",
    "step = 20\n",
    "lr = 0.01\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y) ** 2).sum()\n",
    "    l.backward()\n",
    "\n",
    "    # 梯度下降\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "\n",
    "    # 梯度清0\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:00.225573Z",
     "start_time": "2022-02-03T06:44:00.209611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  tensor([[ 0.9010, -0.8971]])\n",
      "bias:  tensor([-0.0022])\n"
     ]
    }
   ],
   "source": [
    "print(\"weight: \", conv2d.weight.data)\n",
    "print(\"bias: \", conv2d.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征图和感受野\n",
    "\n",
    "二维卷积层输出的二维数组可以看作是**输入在空间维度（宽和高）上某一级的表征**，也叫**特征图（feature map）**。影响元素$x$的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做$x$的**感受野（receptive field）**。    \n",
    "\n",
    "可以通过**更深的卷积神经网络**使**特征图中单个元素的感受野变得更加广阔**，从而捕捉输入上更大尺寸的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充和步幅\n",
    "### 填充      \n",
    "\n",
    "填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:00.241530Z",
     "start_time": "2022-02-03T06:44:00.227568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:00.257487Z",
     "start_time": "2022-02-03T06:44:00.243525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高为5、宽为3的卷积核。在高和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:00.273466Z",
     "start_time": "2022-02-03T06:44:00.260479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输入通道和多输出通道\n",
    "\n",
    "彩色图像在高和宽2个维度外还有`RGB（红、绿、蓝）`3个颜色通道。假设彩色图像的高和宽分别是`h`和`w`（像素），那么它可以表示为一个`3×h×w`的多维数组。我们将大小为3的这一维称为**通道（channel）维**。\n",
    "\n",
    "### 多输入通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.080176Z",
     "start_time": "2022-02-03T06:44:00.275441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 沿着X和K的第0维（通道维）分别计算再相加\n",
    "    res = d2l.corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += d2l.corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res\n",
    "\n",
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输出通道      \n",
    "\n",
    "设卷积核输入通道数和输出通道数分别为$c_i$,$c_o$。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$c_i\\times k_h\\times k_w$ 的卷积核。在做互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.095122Z",
     "start_time": "2022-02-03T06:44:01.082163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])\n",
    "\n",
    "#我们将核数组K同K+1（K中每个元素加一）和K+2连结在一起来构造一个输出通道数为3的卷积核。\n",
    "K = torch.stack([K, K + 1, K + 2])\n",
    "K.shape # torch.Size([3, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.110082Z",
     "start_time": "2022-02-03T06:44:01.096120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1×1卷积层\n",
    "\n",
    "卷积窗口形状为$1\\times1（k_h=k_w=1)$的多通道卷积层,通常称之为1×11×1卷积层。\n",
    "\n",
    "因为使用了最小窗口，1×1卷积失去了卷积层可以**识别高和宽维度上相邻元素构成的模式的功能**。实际上，1×11×1卷积的主要计算**发生在通道维上**。\n",
    "\n",
    "假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么$1\\times 1$卷积层的作用与全连接层等价。    \n",
    "\n",
    "在之后的模型里我们将会看到$1\\times 1$卷积层被当作保持高和宽维度形状不变的全连接层使用。于是，可以通过**调整网络层之间的通道数来控制模型复杂度**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.126042Z",
     "start_time": "2022-02-03T06:44:01.111079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\n",
    "    return Y.view(c_o, h, w)\n",
    "\n",
    "X = torch.rand(3, 3, 3)\n",
    "K = torch.rand(2, 3, 1, 1)\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "(Y1 - Y2).norm().item() < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化层\n",
    "\n",
    "图像物体边缘检测应用中，构造**卷积核**从而**精确地找到了像素变化的位置**。        \n",
    "\n",
    "**实际图像**里，我们感兴趣的物体**不会总出现在固定位置**：即使我们连续拍摄同一个物体也极有可能出现像素位置上的偏移。这会导致**同一个边缘对应的输出**可能**出现在卷积输出$Y$中的不同位置**，进而对后面的模式识别造成不便。\n",
    "\n",
    "- **池化（pooling）层**，它的提出是为了**缓解卷积层对位置的过度敏感性**。\n",
    "\n",
    "### 池化层前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.141997Z",
     "start_time": "2022-02-03T06:44:01.127037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#池化层的前向计算实现在pool2d函数里\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()       \n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.157954Z",
     "start_time": "2022-02-03T06:44:01.142994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充和步幅\n",
    "同卷积层一样，池化层也可以在输入的高和宽两侧的填充并调整窗口的**移动步幅**来改变输出形状。池化层填充和步幅与卷积层填充和步幅的工作机制一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.172914Z",
     "start_time": "2022-02-03T06:44:01.158951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，`MaxPool2d`实例里**步幅和池化窗口形状相同**。下面使用形状为`(3, 3)`的池化窗口，默认获得形状为`(3, 3)`的步幅。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.187873Z",
     "start_time": "2022-02-03T06:44:01.173911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.203831Z",
     "start_time": "2022-02-03T06:44:01.188871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手动指定步幅和填充。\n",
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.219789Z",
     "start_time": "2022-02-03T06:44:01.204829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#指定非正方形的池化窗口，并分别指定高和宽上的填充和步幅。\n",
    "pool2d = nn.MaxPool2d((2, 4), padding=(1, 2), stride=(2, 3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多通道   \n",
    "在处理多通道输入数据时，池化层**对每个输入通道分别池化**，而不是像卷积层那样将各通道的输入按通道相加。这意味着**池化层的输出通道数与输入通道数相等**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.235746Z",
     "start_time": "2022-02-03T06:44:01.221783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), dim=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:44:01.251704Z",
     "start_time": "2022-02-03T06:44:01.236744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 池化后，我们发现输出通道数仍然是2。\n",
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "144px",
    "width": "225px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "832.4px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
